{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 Fabian Hofmann\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# IFTM for Video Generation\n",
    "\n",
    "This notebook serves as an introduction (not an evaluation) of IFTM using video generation techniques.\n",
    "\n",
    "Identity Function and Threshold Model (IFTM) by Schmidt et al. is an anomaly detection approach that utilizes identity functions and forecasting mechanisms to detect anomalies, by either reconstructing the current datapoint or forecasting a future one. Then the predicted value is compared to the actual data by a reconstruction or prediction error function. To detect anomalies, a threshold is applied to the result -- if it exceeds the threshold it is anomaly, else it is not.\n",
    "\n",
    "We provide IFTM for video generation as a wrapper around *any* kind of Keras model; the code of the framework class can be found [here](https://gitlab.tubit.tu-berlin.de/sulandir/Thesis/blob/master/src/iftm/iftm.py). Threshold for our IFTM implementation is exclusively trained by using cumulative aggregation (CA), simply because the Keras model is assumed to be trained in batch-mode/offline as well.\n",
    "\n",
    "##### Sources\n",
    "- [IFTM by Schmidt et al.](https://www.researchgate.net/publication/327484223_IFTM_-_Unsupervised_Anomaly_Detection_for_Virtualized_Network_Function_Services)\n",
    "- [Our implementation of IFTM](https://gitlab.tubit.tu-berlin.de/sulandir/Thesis/blob/master/src/iftm/iftm.py)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.5.0-dev20201111'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from src.io_.batch_generator import UniformBatchGenerator, BatchLoader\n",
    "from src.models.vgan import *\n",
    "from src.models.iftm import IFTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "base_input_path = \"../../data/upCam/preprocessed_128_64/\"\n",
    "base_output_path = \"../../output/models/iftm/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Init batch generator for training and testing\n",
    "\n",
    "The 5th day is used for \"testing\" (not really testing, but just seeing how well the model classifies unknown normal data)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "days_training = [\"00\", \"01\", \"02\", \"03\"]\n",
    "day_paths_training = [base_input_path + day + \"/\" for day in days_training]\n",
    "training_generator = UniformBatchGenerator(day_paths=day_paths_training, batch_size=64, sample_size=8, subsample_size=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "days_testing = [\"04\"]\n",
    "day_paths_testing = [base_input_path + day + \"/\" for day in days_testing]\n",
    "testing_generator = UniformBatchGenerator(day_paths=day_paths_testing, batch_size=64, sample_size=8, subsample_size=7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C-VGAN Models\n",
    "\n",
    "C-VGAN models are built and trained just like in [vgan_conditional_3d_2.ipynb](https://gitlab.tubit.tu-berlin.de/sulandir/Thesis/blob/master/src/models/vgan_conditional_3d_2.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def make_generator_model() -> keras.Model:\n",
    "    inputs: tf.Tensor = keras.Input(shape=(7, 64, 128, 3))\n",
    "\n",
    "    e_3d = make_encoder_foreground_stream(inputs)\n",
    "    f, m = make_conditional_foreground_stream(e_3d)\n",
    "\n",
    "    e_2d = make_encoder_background_stream(inputs)\n",
    "    b = make_conditional_background_stream(e_2d)\n",
    "\n",
    "    outputs = make_generator_stream_combiner(f, m, b)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"c_vgan_generator\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "c_vgan_generator = make_generator_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "c_vgan_discriminator = make_discriminator_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss and optimizers init"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "mean_abs_err = tf.keras.losses.MeanAbsoluteError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "LAMBDA = 10\n",
    "\n",
    "def generator_loss(fake_output, input_videos, generated_videos):\n",
    "    fake_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    reconstruction_loss = mean_abs_err(input_videos, generated_videos[:,:7]) * LAMBDA\n",
    "    return fake_loss + reconstruction_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save checkpoints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "checkpoint_dir = base_output_path + \"training_checkpoints/\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=c_vgan_generator,\n",
    "                                 discriminator=c_vgan_discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the training loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    input_videos, real_videos = batch\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_videos = c_vgan_generator(input_videos, training=True)\n",
    "\n",
    "        real_output = c_vgan_discriminator(real_videos, training=True)\n",
    "        fake_output = c_vgan_discriminator(generated_videos, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output, input_videos, generated_videos)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, c_vgan_generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, c_vgan_discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, c_vgan_generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, c_vgan_discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "def train(epochs):\n",
    "    # Load latest checkpoint if available\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    checkpoint.restore(latest_checkpoint)\n",
    "    if latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(latest_checkpoint))\n",
    "        return\n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Init batch loader for this epoch\n",
    "        batch_loader = BatchLoader(training_generator, max_queue_size=32, no_workers=4)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Train models over the entire batch each epoch\n",
    "        for _ in range(len(batch_loader)):\n",
    "            train_step(batch_loader.get_batch())\n",
    "\n",
    "        # Save the model every 2 epochs\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))\n",
    "\n",
    "        # Cleanup\n",
    "        batch_loader.shutdown_workers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model\n",
    "\n",
    "Train C-VGAN for a single epoch to get some results for IFTM and not just random prediction. Actual training is done during evaluation in another notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n",
      "Time for epoch 1 is 985.5255591869354 sec\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IFTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define the error function\n",
    "\n",
    "In the original IFTM paper L2 was utilized to compute the reconstruction error. For evaluation purposes we chose to stick to L1 however, because that term was minimized during training (as in the original VGAN paper). But, because only the forecast frame matters, we exclude the (seven) reconstructed frames from the error and focus on the 8th frame of the generated video (and its actual counterpart)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "reconstruction_err = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "def error_function(predicted: tf.Tensor, actual: tf.Tensor) -> tf.Tensor:\n",
    "    predicted = tf.reshape(predicted[:,-1], shape=[predicted.shape[0],-1])\n",
    "    actual = tf.reshape(actual[:,-1], shape=[actual.shape[0],-1])\n",
    "    return reconstruction_err(predicted, actual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Init and train IFTM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "iftm = IFTM(c_vgan_generator, error_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training data that was used to train the C-VGAN model is now rerun on the model to compute the training error to train the threshold model of IFTM as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for TM training is 301.5885262489319 sec\n"
     ]
    }
   ],
   "source": [
    "start_tm_training = time.time()\n",
    "iftm.train_threshold(training_generator, max_queue_size=128, no_workers=4)\n",
    "\n",
    "print('Time for TM training is {} sec'.format(time.time() - start_tm_training))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print out the threshold:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056033224\n"
     ]
    }
   ],
   "source": [
    "print(iftm.threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for IFTM testing is 75.47670412063599 sec\n"
     ]
    }
   ],
   "source": [
    "start_iftm_testing = time.time()\n",
    "\n",
    "testing_batches = BatchLoader(testing_generator, max_queue_size=32, no_workers=4)\n",
    "predictions = []\n",
    "for _ in range(len(testing_batches)):\n",
    "    b_x, b_y = testing_batches.get_batch()\n",
    "    _, p = iftm.predict(b_x, b_y)\n",
    "    predictions.append(p)\n",
    "testing_batches.shutdown_workers()\n",
    "\n",
    "print('Time for IFTM testing is {} sec'.format(time.time() - start_iftm_testing))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Count and output the number of \"false\" (0, normal) and \"true\" (1, anomaly) predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18230 35530]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(predictions).flatten()\n",
    "p_count = np.bincount(predictions)\n",
    "\n",
    "print(p_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7d957dfd",
   "language": "python",
   "display_name": "PyCharm (Thesis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}