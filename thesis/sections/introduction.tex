\chapter{Introduction} \label{chap:introduction} % 1-3 pages

% Introduction, Motivation
With the increase in digitization in all domains, new additional challenges arrive in terms of data processing and analysis. The amount of data that needs to be analyzed results in a growth in demand for experts and warrants the need for automation of certain tasks. This phenomenon also appears in the surveillance domain: Due to the falling prices for closed-circuit television (CCTV)\nomenclature{CCTV}{Closed-circuit television} systems, even end users can buy the necessary cameras and devices to monitor the surroundings of their houses. Traffic analysis and orchestration, crime prevention and solving, but also surveillance for assisted living, are some of the many fields in which CCTV systems are applied \cite{fleck2010privacy, bruce2001matching}. And with the increase of video resolution, better night vision, and a wider field of view, the quality of the collected data has also improved over the years \cite{kruegle2011cctv}. 

% Problem
However there are hurdles, even beyond the concerns for privacy and data protection \cite{vlahos2009surveillance}: In 2009 and just in the US, nearly 4 billion hours of video footage were generated by 30 million cameras per week. In 2020, London, it is estimated that over 500,000 CCTV cameras are spread over the city, both private and cameras in public hands\footnote{\url{https://www.caughtoncamera.net/news/how-many-cctv-cameras-in-london/}}. As the surveillance devices proliferate, so did various machine learning approaches for video analysis, especially video anomaly detection (VAD)\nomenclature{VAD}{Video anomaly detection}. In that case, the crucial challenge is to automatically detect unusual, uncommon, or irregular events in video streams \cite{xiang2008video, saligrama2012video, xu2017detecting}. These events can range from a stopped car on a highway, to a person jaywalking, to a collapsed elderly in a nursing home. Some of these events are simple enough to be recognized by humans, even infants \cite{woodward2009infants}, but others proof more challenging. Especially for an anomaly detection system (ADS)\nomenclature{ADS}{Anomaly detection system}, that usually cannot be trained on many anomalous events but only normal video, while the variety and the kinds of the anomalies are usually not known in advance. In addition for VAD, anomaly events often stretch across multiple consecutive frames. Also identifying the context in which events happen is non trivial \cite{liu2020enhancing}, while the definition of an anomalous behavior often depends on the context. 

Lastly, the acquiring of large-scale data sets to train VAD models is difficult as well: Data sets that contain anomalies, such as traffic incidents or illegal activities rarely can be acquired due to legal constraints. And, because of the requirement of the detection of contextual anomalies within video feeds, data sets for action recognition are often not really usable; these usually consist of a diverse collection of very short videos that are downloaded from the internet. A data set captured from one or multiple cameras, which collected video data over several hours if not days, is required instead. This would allow models to learn different contexts and temporal coherences.\\

% Contribution
This thesis presents an anomaly detection method for video streams, that builds on the IFTM (Identify function threshold model)\nomenclature{IFTM}{Identify function threshold model} framework. IFTM uses behavior learning to model the normal behavior of a given data stream \cite{schmidt2018iftm}. Based on the trained model, new values can be used to forecast future values of the stream, and high differences to the actual monitored values are classified as anomalies. To model the normal behavior of video streams for IFTM, we present a modified version of a generative adversarial network for video (VGAN)\nomenclature{VGAN}{Generative adversarial network for video} \cite{vondrick2017generating}. As video generation techniques usually generate generic scene dynamics without predetermined input, i.e. they transform random noise in their latent space to video frames, the VGAN model is made conditional on a number of past frames to generate future ones. This modified unsupervised video prediction model is then integrated into the IFTM framework and the entire system is evaluated based on its performance to detect anomalies of different kinds on video data. Metrics such as F1, precision, recall, and other metrics are used to rate the quality of its predictions. In addition, the video generation model itself is evaluated based on its ability to generate real looking videos from the test data of the data set. In the latter case, training and validation loss metrics and visual evaluation are used to determine the quality of the model. Training and evaluation is done on a large-scale data set that we created with over 240 hours of unlabeled videos, captured over two groups of consecutive days, and a smaller but labeled set of videos for evaluation.\\

% Outline
The rest of the thesis is organized as follows: In Chapter \ref{chap:background} we show the background of this work and the concepts the research is based on. An introduction to CCTV systems, the different classes of anomaly detection techniques, the general types of anomalies, and generative adversarial networks (GANs)\nomenclature{GAN}{Generative adversarial network} is provided. Chapter \ref{chap:contribution} starts with the presentation of our use case, and then continues with the introduction to VGAN and our modifications to it to support video forecasting, before its integration into the IFTM framework is explained. In the same chapter, we also provide insight into our data set, and the anomaly detection system that we built to test and evaluate our models. Then, in Chapter \ref{chap:results}, we present our evaluation methods for our modified video generation forecasting model and IFTM for VAD, before we show and discuss our results. Both relevant and similar work as well as other approaches for VAD are described in Chapter \ref{chap:state_of_the_art}. We also showcase approaches for future frame prediction that could be integrated into IFTM as well. Finally our conclusions of the research and the outlook for future work are provided in Chapter \ref{chap:conclusion}.